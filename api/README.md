# Gamatrain AI Server

ğŸ¤– Ø³Ø±ÙˆØ± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ Gamatrain Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª RAGØŒ Ø­Ø§ÙØ¸Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡ Ùˆ Ø§Ø¬Ø±Ø§ Ø¨Ø¯ÙˆÙ† GPU.

## âœ¨ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§

### RAG (Retrieval-Augmented Generation)
- Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¯Ø± 2000+ Ø¨Ù„Ø§Ú¯ Ùˆ Ù…Ø­ØªÙˆØ§ÛŒ ÙˆØ¨Ø³Ø§ÛŒØª
- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² embedding model Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†Ù‡ (`intfloat/multilingual-e5-large`)
- Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ index Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨Ø§Ù„Ø§ØªØ±

### Conversation Memory
- Ø°Ø®ÛŒØ±Ù‡ 5 Ù¾ÛŒØ§Ù… Ø¢Ø®Ø± Ù‡Ø± session
- Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ø³ÙˆØ§Ù„Ø§Øª follow-up Ù…Ø«Ù„ "Can you explain more?"
- ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø± Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ù…Ú©Ø§Ù„Ù…Ù‡ Ù‚Ø¨Ù„ÛŒ

### Production Ready
- Ø§Ø¬Ø±Ø§ Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ GPU
- Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Groq API (Ø±Ø§ÛŒÚ¯Ø§Ù† Ùˆ Ø³Ø±ÛŒØ¹)
- Streaming response Ø¨Ø§ Ø§Ù†ÛŒÙ…ÛŒØ´Ù† ØªØ§ÛŒÙ¾

## ğŸ—ï¸ Ù…Ø¹Ù…Ø§Ø±ÛŒ

```
Frontend (Nuxt) â†’ Production Server (CPU) â†’ Groq API
                         â†“
                  RAG + Memory + Follow-up
                  (LlamaIndex + Embeddings)
                         â†“
                  Gamatrain API (Blogs, Schools)
```

## ğŸš€ Ù†ØµØ¨ Ùˆ Ø§Ø¬Ø±Ø§

### Development

```bash
cd api
pip install -r requirements-production.txt
cp .env.example .env
# Edit .env with your GROQ_API_KEY
python llm_server_production.py
```

### Docker

```bash
docker-compose -f docker-compose.production.yml up -d
```

## âš™ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª (.env)

```env
# Provider
PROVIDER=groq

# Groq API (FREE - https://console.groq.com)
GROQ_API_KEY=your_key_here
GROQ_MODEL=llama-3.1-8b-instant

# Server
HOST=0.0.0.0
PORT=8002

# RAG
SIMILARITY_THRESHOLD=0.45
MAX_TOKENS=1024

# Gamatrain API
GAMATRAIN_API_URL=https://185.204.170.142/api/v1
```

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/v1/query` | Ø§Ø±Ø³Ø§Ù„ Ø³ÙˆØ§Ù„ (Ø¨Ø§ streaming) |
| `POST` | `/v1/chat/completions` | OpenAI-compatible endpoint |
| `POST` | `/v1/refresh` | Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ RAG index |
| `DELETE` | `/v1/session/{id}` | Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø­Ø§ÙØ¸Ù‡ session |
| `GET` | `/health` | Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª Ø³Ø±ÙˆØ± |
| `GET` | `/v1/debug/search?q=...` | Debug: Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø§ score |
| `GET` | `/v1/debug/list-blogs?search=...` | Debug: Ù„ÛŒØ³Øª Ø¨Ù„Ø§Ú¯â€ŒÙ‡Ø§ |

### Ù†Ù…ÙˆÙ†Ù‡ Request

```bash
# Query with streaming
curl -X POST "http://localhost:8002/v1/query" \
  -H "Content-Type: application/json" \
  -d '{"query": "What is machine learning?", "session_id": "user123"}'

# Refresh index
curl -X POST "http://localhost:8002/v1/refresh"
```

## ğŸ“ Ø³Ø§Ø®ØªØ§Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§

```
api/
â”œâ”€â”€ llm_server_production.py  # Ø³Ø±ÙˆØ± Ø§ØµÙ„ÛŒ (Ø¨Ø¯ÙˆÙ† GPU)
â”œâ”€â”€ llm_server.py             # Ø³Ø±ÙˆØ± ØªÙˆØ³Ø¹Ù‡ (Ø¨Ø§ Ollama)
â”œâ”€â”€ requirements-production.txt
â”œâ”€â”€ .env
â””â”€â”€ storage/                  # RAG index cache
```

## ğŸ“ Ù†Ú©Ø§Øª Ù…Ù‡Ù…

1. **Refresh Index**: Ø¨Ø¹Ø¯ Ø§Ø² Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù† Ø¨Ù„Ø§Ú¯ Ø¬Ø¯ÛŒØ¯:
   ```bash
   curl -X POST "http://localhost:8002/v1/refresh"
   ```

2. **Groq API**: Ø±Ø§ÛŒÚ¯Ø§Ù† Ø§Ø³Øª ÙˆÙ„ÛŒ rate limit Ø¯Ø§Ø±Ø¯ (30 req/min)

3. **Embedding Model**: Ø§ÙˆÙ„ÛŒÙ† Ø§Ø¬Ø±Ø§ ~2GB Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÛŒÚ©Ù†Ø¯

4. **Session Management**: Ù‡Ø± Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§ÛŒØ¯ `session_id` ÛŒÚ©ØªØ§ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯

## ğŸ”§ Troubleshooting

**Ù…Ø´Ú©Ù„: RAG Ù…Ø­ØªÙˆØ§ Ù¾ÛŒØ¯Ø§ Ù†Ù…ÛŒÚ©Ù†Ø¯**
- Index Ø±Ø§ refresh Ú©Ù†ÛŒØ¯
- Threshold Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ù‡ÛŒØ¯ (Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: 0.45)

**Ù…Ø´Ú©Ù„: Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ Ø§Ø³Øª**
- `MAX_TOKENS` Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡ÛŒØ¯

**Ù…Ø´Ú©Ù„: Ø®Ø·Ø§ÛŒ API**
- `GROQ_API_KEY` Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯
- Rate limit Ø±Ø§ Ú†Ú© Ú©Ù†ÛŒØ¯

## ğŸ“„ License

MIT
